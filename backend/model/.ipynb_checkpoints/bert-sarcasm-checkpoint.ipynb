{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f24e3b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\witch\\anaconda3\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "import sys\n",
    "from IPython.core import ultratb\n",
    "sys.excepthook = ultratb.FormattedTB(color_scheme='Linux', call_pdb=False)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('prajjwal1/bert-tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c53f79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, X, Y):\n",
    "\n",
    "        self.labels = np.array(Y)\n",
    "        self.texts = [tokenizer(text, \n",
    "                                padding='max_length', max_length = 512,\n",
    "                                # truncation=True,\n",
    "                                return_tensors=\"pt\") for text in X]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a2dead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('prajjwal1/bert-tiny')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(128, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77506f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X,Y, learning_rate, epochs, batch_size):\n",
    "\n",
    "    train = Dataset(X,Y)\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size, shuffle=True)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "        total_acc_train = 0\n",
    "        total_loss_train = 0\n",
    "\n",
    "    for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "        train_label = train_label.to(device)\n",
    "        mask = train_input['attention_mask'].to(device)\n",
    "        input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "      \n",
    "        batch_loss = criterion(output, train_label)\n",
    "        total_loss_train += batch_loss.item()\n",
    "      \n",
    "        acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_acc_train += acc\n",
    "\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "      print(f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(X): .3f} | Train Accuracy: {total_acc_train / len(X): .3f}')\n",
    "\n",
    "\n",
    "def evaluate(model, X,Y, batch_size):\n",
    "\n",
    "    test = Dataset(X, Y)\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size,shuffle=False)\n",
    "\n",
    "    device = torch.device(\"cpu\")\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "    for test_input, test_label in test_dataloader:\n",
    "\n",
    "        test_label = test_label.to(device)\n",
    "        mask = test_input['attention_mask'].to(device)\n",
    "        input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "        output = model(input_id, mask)\n",
    "        y_pred.append(output.argmax(dim=1))\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a916fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"./Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
    "\n",
    "X = df['headline']\n",
    "Y = df['is_sarcastic']\n",
    "\n",
    "data_split = int(df.shape[0] * 0.75)\n",
    "X_train, X_test = X[:data_split], X[data_split:]\n",
    "y_train, y_test = Y[:data_split], Y[data_split:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "044ee750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f818d97bd1441d5960145af641b24ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\witch\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\witch\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 671/671 [09:32<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1 | Train Loss:  0.015 | Train Accuracy:  0.762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1 #5\n",
    "batch_size = 32\n",
    "model = BertClassifier()\n",
    "LR = 1e-4\n",
    "              \n",
    "train(model, X_train, y_train, LR, EPOCHS, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e54805f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      3745\n",
      "           1       0.86      0.86      0.86      3410\n",
      "\n",
      "    accuracy                           0.87      7155\n",
      "   macro avg       0.87      0.87      0.87      7155\n",
      "weighted avg       0.87      0.87      0.87      7155\n",
      "\n",
      "0.8671640388553262\n"
     ]
    }
   ],
   "source": [
    "y_pred = evaluate(model, X_test,y_test, batch_size)\n",
    "\n",
    "y_pred_ = torch.cat(y_pred, dim=0)\n",
    "\n",
    "y_pred_=y_pred_.cpu().detach().numpy()\n",
    "\n",
    "print(classification_report(y_test.values, y_pred_))\n",
    "print(roc_auc_score(y_test, y_pred_))\n",
    "\n",
    "# ummm so this is from https://github.com/nguyenduchuyvn/Udacity-Data-Scientist-Nanodegree/tree/main/MyCapstoneProject\n",
    "# :3 :3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c9cc736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4.0045, 0.0000]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mypredict(x):\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        texts = tokenizer(x, padding='max_length', max_length = 512, return_tensors=\"pt\")\n",
    "        mask = texts['attention_mask'].to(device)\n",
    "        input_id = texts['input_ids'].squeeze(1).to(device) # squueze remove all dimensions size 1\n",
    "        output = model(input_id, mask)\n",
    "        \n",
    "        return output\n",
    "mypredict('You are so pretty.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "90737591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor([[3.8836, 0.0000]], grad_fn=<ReluBackward0>) <ReluBackward0 object at 0x0000023D4995FEE0>\n",
      "<class 'torch.Tensor'> tensor(0.0204, grad_fn=<NllLossBackward0>) <NllLossBackward0 object at 0x0000023D4995FEE0>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.8836, 0.0000]], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def single_train(x):\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    texts = tokenizer(x, padding='max_length', max_length = 512, return_tensors=\"pt\")\n",
    "    mask = texts['attention_mask'].to(device)\n",
    "    input_id = texts['input_ids'].squeeze(1).to(device) # squueze remove all dimensions size 1\n",
    "    \n",
    "    output = model(input_id, mask)\n",
    "    print(type(output), output, output.grad_fn)\n",
    "\n",
    "    batch_loss = criterion(output, torch.tensor([0]))\n",
    "    print(type(batch_loss), batch_loss, batch_loss.grad_fn)\n",
    "    \n",
    "    model.zero_grad()\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output\n",
    "single_train('You are so pretty.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fa6fc63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"sarcasm.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b4b8a37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertClassifier().to(torch.device(\"cpu\"))\n",
    "model.load_state_dict(torch.load(\"sarcasm.model\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
